SAVE_DIR="leaderboard/results"

BATCH_SIZE=40
CONFIG="configs/content_moderation.json"

AWS_GUARDRAIL_ID=
AZURE_ENDPOINT=
LAKERA_PROJECT_ID=
source .venv/bin/activate

# Supervisors that don't require used_for (run both datasets via config)
python run_eval.py --model-id="azure-analyze-text" --type="rest" --model-kwarg endpoint=$AZURE_ENDPOINT --save_dir=$SAVE_DIR --lab="azure" --model_name="analyze-text" --config=$CONFIG --batch_size=$BATCH_SIZE
python run_eval.py --model-id="lakeraguard-default" --type="rest" --model-kwarg project_id=$LAKERA_PROJECT_ID --save_dir=$SAVE_DIR --lab="lakera" --model_name="lakera-guard_default" --config=$CONFIG --batch_size=$BATCH_SIZE
python run_eval.py --model-id="openai-moderation" --type="rest" --save_dir=$SAVE_DIR --lab="openai" --model_name="omni-moderation" --config=$CONFIG --batch_size=$BATCH_SIZE
python run_eval.py --model-id="together-virtueguard-text-lite" --type="rest" --save_dir=$SAVE_DIR --lab="virtue-ai" --model_name="virtueguard-text-lite" --config=$CONFIG --batch_size=$BATCH_SIZE
python run_eval.py --model-id="together-llama-guard-4b" --type="rest" --save_dir=$SAVE_DIR --lab="meta" --model_name="llama-guard-4-12b" --config=$CONFIG --batch_size=$BATCH_SIZE

# Supervisors that require used_for (run per-dataset)
for USED_FOR in input output; do
    python run_eval.py --model-id="anthropic-classification" --type="rest" --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="anthropic" --model_name="claude-sonnet-4-5" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="anthropic-classification" --type="rest" --model-kwarg model=claude-haiku-4-5 --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="anthropic" --model_name="claude-haiku-4-5" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="bedrock-guardrail" --type="rest" --model-kwarg source=$USED_FOR --model-kwarg guardrail_identifier=$AWS_GUARDRAIL_ID --save_dir=$SAVE_DIR --lab="aws" --model_name="bedrock-guardrail" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="google-classification" --type="rest" --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="google" --model_name="gemini-2.5-flash" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="mistral-classification" --type="rest" --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="mistral" --model_name="ministral-3b-2512" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="mistral-classification" --type="rest" --model-kwarg model=mistral-large-2512 --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="mistral" --model_name="mistral-large-3" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="openai-classification" --type="rest" --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="openai" --model_name="gpt-5-nano" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="openai-classification" --type="rest" --model-kwarg model=gpt-5.2-2025-12-11 --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="openai" --model_name="gpt-5.2" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="openrouter-gpt-oss-safeguard" --type="rest" --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="openai" --model_name="gpt-oss-safeguard-20b" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="together-gpt-oss" --type="rest" --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="openai" --model_name="gpt-oss-20b" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="together-gpt-oss" --type="rest" --model-kwarg model=openai/gpt-oss-120b --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="openai" --model_name="gpt-oss-120b" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
    python run_eval.py --model-id="xai-classification" --type="rest" --model-kwarg model=grok-4-1-fast-non-reasoning --model-kwarg used_for=$USED_FOR --save_dir=$SAVE_DIR --lab="x-ai" --model_name="grok-4-1-fast-non-reasoning" --dataset-id="bells-o-project/content-moderation-$USED_FOR" --usage="content_moderation" --truthy-value="!Benign" --batch_size=$BATCH_SIZE
done