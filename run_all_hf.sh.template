SAVE_DIR="leaderboard/results"
USED_FOR="input"
source .venv/bin/activate

# all HF supervisors for the benchmark
python run_eval.py --name="google/shieldgemma-2b" --type="hf" --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="google/shieldgemma-27b" --type="hf" --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="openai/gpt-oss-safeguard-120b" --type="hf" --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="saillab/xguard" --type="hf" --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="qwen/qwen3guard-gen-8b" --type="hf" --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="qwen/qwen3guard-gen-0.6b" --type="hf" --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="rakancorle1/thinkguard" --type="hf" --save_dir=$SAVE_DIR --kwargs="{\"used_for\":\"$USED_FOR\"}" --dataset=$USED_FOR
python run_eval.py --name="allenai/wildguard" --type="hf" --save_dir=$SAVE_DIR --kwargs="{\"used_for\":\"$USED_FOR\"}" --dataset=$USED_FOR
python run_eval.py --name="toxicityprompts/polyguard-ministral" --type="hf" --save_dir=$SAVE_DIR --kwargs="{\"used_for\":\"$USED_FOR\"}" --dataset=$USED_FOR
python run_eval.py --name="toxicityprompts/polyguard-qwen" --type="hf" --save_dir=$SAVE_DIR --kwargs="{\"used_for\":\"$USED_FOR\"}" --dataset=$USED_FOR
python run_eval.py --name="ibm-granite/granite-guardian-3.3-8b" --type="hf" --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="govtech/lionguard-2" --type="hf" --kwargs='{"backend":"transformers"}' --save_dir=$SAVE_DIR --dataset=$USED_FOR
python run_eval.py --name="nvidia/llama-3.1-nemotron-safety-guard-8b-v3" --type="hf" --save_dir=$SAVE_DIR --kwargs="{\"used_for\":\"$USED_FOR\"}" --dataset=$USED_FOR

